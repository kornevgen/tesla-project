\documentclass{article}
\usepackage[cp1251]{inputenc}
\usepackage[russian]{babel}
\usepackage{pscyr}
\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amssymb}

\title{Основная теоретическая часть диссертации}
\author{}
\date{}

\textwidth=16cm \oddsidemargin=0cm

\newtheorem{theorem}{Теорема}
\newtheorem{lemma}{Лемма}

\begin{document}
\maketitle

Введение: Исходная постановка задачи -- последовательность тестовых
ситуаций + что надо вычислить. Типы кэш-памяти: полностью
ассоциативный, прямого отображения и наборно-ассоциативный.

\section*{Результаты}
\begin{enumerate}
\item новый метод генерации тестовых данных (т.н. \emph{совместная
генерация ограничений}) для тестирования инструкций обращения с
памятью; позволяет снизить сложность написания генератора,
рассматривая наиболее часто встречающиеся механизмы работы с памятью
и используя привычные общедоступные решатели задач;
\item новый метод описания тестовых ситуаций в кэш-памяти с
использованием конечных множеств тегов адресов;
\item компактное описание стратегии LRU с помощью ограничений
\end{enumerate}

\section{Использование уравнений на множества для описания тестовых
ситуаций в кэш-памяти}\label{cache_sets}

\begin{abstract}
В этом разделе идет речь о том, как решать задач генерации тестовых
данных для последовательности тестовых ситуаций в кэш-памяти. Раздел
содержит новые результаты по формальному представлению тестовой
ситуации в кэш-памяти, новый алгоритм генерации уравнений для их
описания и новое исследование этих уравнений. В разделе идет речь о
<<кэш-памяти>> в широком смысле, т.е. не о подсистеме
микропроцессора, а о \emph{хранилищах} объектов, индексированных
\emph{тегами}, к которому производится обращение по адресу и
вытеснение в случае отсутствия данных по нужному адресу.
\end{abstract}

Общая идея решения поставленной задачи -- по тестовому шаблону
построить систему уравнений и решить ее. Поскольку решением задачи
является начальное состояние микропроцессора (значения регистров
перед началом исполнения тестового шаблона, значения ячеек
кэш-памяти и других подсистем микропроцессора перед началом
исполнения тестового шаблона), то в системе в качестве свободных
переменных будут представлены элементы начального состояния
микропроцессора.

Рассмотрим идеи, исходя из которых предлагается строить систему
уравнений. Каждая инструкция может поменять значение регистров или
содержимое кэш-памяти и других подсистем. Значения регистров будут
представляться <<скалярными>> переменными. Содержимое кэш-памяти
будет представляться \emph{множеством ячеек} кэш-памяти. Содержимое
кэш-памяти можно разделить на две структуры -- структура для
хранения кэшированных данных и структура для хранения тегов адресов
кэшированных данных. Для моделирования тестовых ситуаций в
кэш-памяти будет использоваться только структура для хранения тегов.
Структура для хранения кэшированных данных не нужна, поскольку все
данные могут считаться находящимися в памяти.

\begin{figure}[h] \center
  \includegraphics[width=0.5\textwidth]{mpset}\\
  \caption{Представление состояния микропроцессора}\label{mpset}
\end{figure}

Теперь можно подходить ближе к тому, как эту систему составлять. Но
перед этим напомню тестовые ситуации инструкций, работающих с
кэш-памятью (для описания будут использоваться следующие переменные:
$L$ -- текущее состояние кэш-памяти (множество тегов), $x$ --
(физический) адрес данных в инструкции):
\begin{itemize}
\item \emph{кэш-попадание} происходит в том случае, когда данные по
данному адресу присутствуют в кэш-памяти; по такой тестовой ситуации
предлагается строить уравнение $x \in L$;
\item \emph{кэш-промах} происходит в случае, когда данные по данному
адресу не присутствуют в кэш-памяти; для этой тестовой ситуации
составляется уравнение $x \notin L$.
\end{itemize}

Физический адрес данных в инструкции ($x$) может быть составлен из
аргументов инструкции (обычно регистров). При этом следует
использовать значения регистров в момент данной инструкции
(применить для регистров Static single assignment form,
SSA).

Рассмотрим, как составить выражение для $L$ в каждой инструкции
методом индукции. $L$ для первой инструкции есть начальное
содержимое кэш-памяти, это переменная величина в системе уравнений.
Пусть выражение для очередной инструкции $L$, а для следующей --
$L'$. Тогда если очередная инструкция -- кэш-попадание, то $L'
\equiv L$ (так как содержимое не меняется), а если очередная
инструкция -- кэш-промах с адресом $x$, то $L' \equiv (L \setminus
\{x'\} \cup \{x\})$ (так как в кэш-память при промахе добавляются
данные по нужному адресу, а некоторые данные вытесняются, $x'$ есть
адрес вытесняемых данных). Для новой переменной $x'$ добавим в
систему такие уравнения: $x' \in L \wedge displaced(x') \wedge R(x)
= R(x')$, новый предикат $displaced$ описывает \emph{стратегию
вытеснения}, т.е. правило, по которому в кэш-памяти выбираются
данные, которые следует удалить, а на их место поместить данные,
вызвавшие промах. Для кэш-памяти прямого отображения общезначимо
утверждение $(R(x) = R(x')) \rightarrow displaced(x')$, поэтому для
такого типа кэш-памяти уравнение $displaced(x')$ убирается из
системы. Функциональный символ $R$ используется для задания набора,
которому относится адрес, в кэш-памяти прямого отображения и
наборно-ассоциативной кэш-памяти. Возможна такая семантика этого
символа -- $R(x)$ это множество адресов, которые потенциально могут
находиться в том же наборе, что и набор адреса $x$ (верно
утверждение, что адрес не может соответствовать более чем одному
набору и не соответствовать никакому набору вообще, одному набору
могут соответствовать разные адреса). Или такая семантика -- $R(x)$
это номер набора адреса $x$. Для составления уравнений может быть
выбрана любая семантика. Для полностью-ассоциативной кэш-памяти
уравнение $R(x) = R(x')$ является тождественной истиной, поскольку в
нем все адреса соответствуют одному набору.

Следующая теорема описывает выражение для $L$ без использования
индукции и составление ограничений для тестовых ситуаций в
кэш-памяти:
\begin{lemma}\label{L_current}
Пусть $L$ -- выражение для текущего состояния кэш-памяти, $L_0$ --
множество адресов данных, расположенных в кэш-памяти перед
исполнением инструкций тестового шаблона, $\{x_i\}$ -- множество
адресов данных в инструкциях с кэш-промахами, расположенными до
текущей инструкции в том же порядке, что и в тестовом шаблоне,
$\{x'_i\}$ -- множество адресов вытесняемых данных в инструкциях с
кэш-промахами, расположенными до текущей инструкции в том же
порядке, что и в тестовом шаблоне. Тогда
$$L \equiv L_0 \setminus \bigcup_{i} \{x'_i\} \cup \bigcup_{i} ( \{x_i\} \setminus \cup_{j > i} \{x'_j\}).$$
\end{lemma}
\begin{proof}
//TODO

Например, если перед данной инструкцией располагается 3 инструкции с
кэш-промахом, то $L \equiv L_0 \setminus \{x'_1, x'_2, x'_3\} \cup
(\{x_1\} \setminus \{x'_2, x'_3\}) \cup (\{x_2\} \setminus \{x'_3\})
\cup \{x_3\}$.
\end{proof}

\begin{theorem}[Дизъюнктивная форма уравнений для тестовых ситуаций в кэш-памяти]\label{hit_miss_equations}
Пусть $L_0$ -- множество адресов данных, расположенных в кэш-памяти
перед исполнением инструкций тестового шаблона, $\{x_i\}$ --
множество адресов данных в инструкциях с кэш-промахами,
расположенными до текущей инструкции в том же порядке, что и в
тестовом шаблоне, $\{x'_i\}$ -- множество адресов вытесняемых данных
в инструкциях с кэш-промахами, расположенными до текущей инструкции
в том же порядке, что и в тестовом шаблоне. Тогда
\begin{itemize}
\item для инструкции с кэш-попаданием адреса $x$ следует добавить
следующую совокупность уравнений:
$$
\left[
   \begin{array}{l}
    x \in L_0 \wedge x \notin \{x'_1, x'_2, ..., x'_n\} \\
    x = x_1 \wedge x \notin \{x'_2, ..., x'_n\} \\
    x = x_2 \wedge x \notin \{x'_3, ..., x'_n\} \\
    ...\\
    x = x_{n-1} \wedge x \notin \{x'_n\} \\
    x = x_n \\
   \end{array}
  \right.
$$

\item для инструкции с кэш-промахом адреса $x$ (и адресом
вытесненных данных $x'$) следует добавить следующую систему
уравнений:
$$
\left\{
   \begin{array}{l}

  \left[
   \begin{array}{l}
    x \notin L_0 \wedge x \notin \{x_1, x_2, ..., x_n\} \\
    x = x'_1 \wedge x \notin \{x_2, ..., x_n\} \\
    x = x'_2 \wedge x \notin \{x_3, ..., x_n\} \\
    ...\\
    x = x'_{n-1} \wedge x \notin \{x_n\} \\
    x = x'_n \\
   \end{array}
  \right. \\

  { }\\

  \left[
   \begin{array}{l}
    x' \in L_0 \wedge x \notin \{x'_1, x'_2, ..., x'_n\} \\
    x' = x_1 \wedge x \notin \{x'_2, ..., x'_n\} \\
    x' = x_2 \wedge x \notin \{x'_3, ..., x'_n\} \\
    ...\\
    x' = x_{n-1} \wedge x \notin \{x'_n\} \\
    x' = x_n \\
   \end{array}
  \right. \\

  { }\\

  displaced(x')\\

  { }\\

  R(x) = R(x')\\

  \end{array}
\right.
$$

\end{itemize}
\end{theorem}
\begin{proof}
//TODO
\end{proof}

Заметьте, что получившиеся ограничения для кэш-попадания и
кэш-промаха получились очень похожими, хотя изначально у них было
два совершенно противоположных представления. Теперь надо выразить
стратегию вытеснения в виде уравнений на множества тегов.

\subsection{Методика выделения ограничений для описания тестовых
ситуаций с помощью уравнений на множества}

Итак, есть тестовый шаблон, в тестовом шаблоне для некоторой
инструкции добавлена переменная для вытесняемого тега, и для этой
переменной надо записать условие, при котором она будет вытеснена в
данной инструкции. Это условие предлагается записывать в виде
системы (возможно, с дизъюнкциями) уравнений на множества тегов,
которые можно получить, учитывая следующие правила:

\begin{enumerate}
\item переменные не кодируют порядок элементов, только содержимое
кэша;
\item порядок элементов определяется на основе порядка
инструкций, только порядком инструкций (т.е. порядком адресов, к
которым происходит обращение) можно пользоваться для кодирования
различных механизмов упорядочения; рекомендуется использовать то
определение стратегии вытеснение, в котором порядок используется
меньше всего;
\item введение термина \emph{диапазон вытеснения} -- той части
тестового шаблона, которая непосредственно влияет на вытеснение; у
диапазона есть начало на некоторой инструкции или элементе
начального состояния кэш-памяти; конец диапазона вытеснения есть
инструкция, вытесняющая нужный тег; система ограничений может
содержать дизъюнкцию условий, каждое соответствует некоторому
диапазону вытеснения;
\item \emph{(эвристика невложенных диапазонов)} если согласно
выбранному принципу выбора диапазоны вытеснения не могут быть
вложены, скорее всего вы на правильном пути;
\item \emph{(эвристика полноты)} зачастую реальные стратегии
вытеснения основаны на неком свойстве полноты некоторой группы
элементов; эта полнота может быть полезна при формулировании
уравнений;
\item возможно использование функциональных символов
(например, как это сделано с $R$);
\item ориентирование на символьное решение системы уравнений на
множества.
\end{enumerate}

\subsection{Уравнения для некоторых стратегий вытеснения}

Здесь будет представлено, как приведенная выше методика была
применена для выделения уравнений, описывающих следующие стратегии
вытеснения, наиболее часто использующиеся в микропроцессорах -- это
LRU (Least Recently Used), FIFO (First-In First-Out) и Pseudo-LRU.
Стратегия вытеснения Random не рассматривается, ввиду ее
недетерминированности и детерминированности системы уравнений.

\subsubsection{LRU -- Least Recently Used}

LRU (Least Recently Used) -- это стратегия вытеснения, определяющая
вытесняемые данные как наименее используемые. Она эффективна для
алгоритмов, обладающих свойством локальности данных, т.е. чаще
использующих те данные, к которым недавно происходило обращение. Эта
стратегия используется, например, в микропроцессорах архитектуры MIPS~\cite{mips64_II}.

Стратегия вытеснения LRU обычно определяется с использованием
счетчиков обращений. Более подробно, для каждого элемента кэш-памяти
вводится счетчик обращений к нему. Каждое обращение увеличивает
счетчик. Вытесняемым будет элемент с минимальным счетчиком. Однако
описание в виде уравнений на множества изменений значений счетчиков
будет слишком громоздким.

Другой способ описания LRU основан на введении порядка на элементах
набора (т.е. набор представляется списком элементов). После каждой
инструкции элементы переупорядочиваются согласно следующим правилам
(см.рис.~\ref{lru1}):
\begin{itemize}
\item при кэш-попадании элемент, соответствующий адресу инструкции,
перемещается в начало, остальные элементы от первого до данного
сдвигаются на одну позицию;
\item при кэш-промахе вытесняется последний элемент, в начало
вставляется элемент, вызвавший промах.
\end{itemize}

\begin{figure}[h] \center
  \includegraphics[width=0.6\textwidth]{lru1}\\
  \caption{Стратегия вытеснения LRU (w - ассоциативность кэш-памяти) -- реализация на списках}\label{lru1}
\end{figure}

Однако и это описание не подходит, потому как оно существенно
использует порядок элементов.

Третий способ описания LRU основан на выборе последнего обращения к
вытесняемому элементу. Если элемент должен стать LRU, т.е. наиболее
неиспользуемым, все остальные элементы, наоборот, должны быть хотя
бы раз использованы (т.е. к ним должны быть обращения до вытесняющей
инструкции). Иными словами, чтобы элемент был вытеснен, необходимо и
достаточно, чтобы между последним обращением к нему и вытеснением
были обращения ко всем элементам текущего состояния кэш-памяти,
кроме него. Инструкции от последнего обращения к вытеснению образуют
диапазон вытеснения (см. рис.~\ref{lru-ranges}).

\begin{figure}[h] \center
  \includegraphics[width=0.4\textwidth]{lru}\\
  \caption{Диапазоны вытеснения для стратегии вытеснения LRU}\label{lru-ranges}
\end{figure}

Запишем в виде уравнений на множества эту логику. Предикат
$displaced(x')$ будет представлен дизъюнкцией уравнений -- каждый
элемент дизъюнкции соответствует некоторому диапазону вытеснения.
Тогда для диапазона вытеснения к инструкции, обращающейся к адресу
$y$ надо составить такую систему уравнений ($x_1, x_2, ..., x_n$ --
множество адресов, к которым происходят обращения внутри диапазона
вытеснения (как с кэш-попаданиями, так и с кэш-промахами, а также
элементы начального состояния, если диапазон начинается там), $L$ --
выражение для состояния кэш-памяти для инструкции, вытесняющей
$x'$):
$$
\left\{
   \begin{array}{l}
    x' = y \\
    \{x_1, x_2, ..., x_n\} \cap R(y) = (L \setminus \{y\}) \cap R(y)\\
   \end{array}
  \right.
$$

Функциональный символ $R$ используется в смысле множества адресов
того же региона. С использованием следующей леммы упростим эту
систему:
\begin{lemma}\label{LRU_simplification}
Для любых конечных множеств $X$, $Y$ и $Z$ таких, что $X \cap Y
\subseteq Z$, если существует $y$ такой, что $y \in (Y \cap
Z)\setminus X$, то $X \cap Y = (Z \setminus \{y\}) \cap Y
\Leftrightarrow Y \cap ( Z \setminus X ) = \{ y \}$.
\end{lemma}
\begin{proof}
Необходимость. По определению вычитания множеств и коммутативности
операции пересечения множеств $X \cap Y = (Z \setminus \{y\}) \cap Y
\Leftrightarrow X \cap Y = Z \cap Y \cap \overline{\{y\}}$.
Обозначим $A = Z \cap Y$, $B = X \cap Y$. Следовательно, $B = A
\setminus \{y\}$. По условию $y \notin B$ и $y \in A$. Значит, $A =
B \sqcup \{y\}$. Отсюда $A \setminus B = \{y\}$. Осталось показать,
что $A \setminus B = (Z \setminus X ) \cap Y$ : $A \setminus B = A
\cap \overline{B} = Z \cap Y \cap \overline{X \cap Y} = Z \cap Y
\cap (\overline{X} \cup \overline{Y}) = (Z \cap Y \cap \overline{X})
\cup (Z \cap Y \cap \overline{Y}) = Z \cap \overline{X} \cap Y = (Z
\setminus X ) \cap Y$.

Достаточность. Обозначим $A = Z \cap Y$, $B = X \cap Y$. С
использованием определений операций над множествами и их свойств
получаем $X \cap Y \subseteq Z \Leftrightarrow (X \cap Y) \setminus
Z = \varnothing \Leftrightarrow X \cap Y \cap \overline{Z} =
\varnothing \Leftrightarrow X \cap Y \cap (\overline{Z} \cup
\overline{Y}) = \varnothing \Leftrightarrow B \setminus A =
\varnothing$. Кроме того, по условию $A \setminus B = \{y\}$.
Следовательно, $A = (A \setminus B) \cup (A \cup B) = \{y\} \cup (B
\setminus (B \setminus A)) = \{y\} \cup (B \setminus \varnothing) =
\{y\} \cup B$. Таким образом, $A = B \cup \{y\}$. Кроме того, $y
\notin B$, значит, $A = B \sqcup \{y\}$, следовательно, $B = A
\setminus \{y\}$. Подставляя определения множеств $A$ и $B$,
получаем: $X \cap Y = (Z \cap Y) \setminus \{y\} = Z \cap Y \cap
\overline{\{y\}} = (Z \setminus \{y\}) \cap Y$.
\end{proof}

\begin{lemma}[Отсутствие вложенных диапазонов]\label{includedranges}
//TODO
\end{lemma}
\begin{proof}
//TODO
\end{proof}

\begin{lemma}[О выполнимости условий
леммы~\label{LRU_simplification} для диапазонов вытеснения] $L
\supseteq \{x_1, x_2, ..., x_n\} \cap R(y)$
\end{lemma}
\begin{proof}[\proofname~(от противного)]
Пусть среди $x_1, x_2, ..., x_n$ есть $x_i$ такой, что $x_i \notin L
\wedge x_i \in R(y)$. Пусть $L_{i+1}$ -- состояние кэш-памяти после
обращения к $x_i$. Верно, что $x_i \in L_{i+1}$, но $x_i \notin L$,
следовательно, $x_i$ был вытеснен между $x_{i+1}$ и $x_n$. Иными
словами, среди $x_1, x_2, ..., x_n$ есть элемент, чей диапазон
вытеснения вложен в диапазон вытеснения $y$. Но согласно
лемме~\ref{includedranges} это невозможно. Противоречие.
\end{proof}

Таким образом, можно применить лемму~\ref{LRU_simplification} для
упрощения уравнения для LRU:
\begin{theorem}[Уравнение для LRU]\label{LRU_equation}
Тег $x'$ является вытесняемым при стратегии вытеснения LRU в
диапазоне вытеснения из обращения к тегу $y$ и тегами внутри
диапазона вытеснения $\{x_1, x_2, ..., x_n\}$, если
$$
\left\{
   \begin{array}{l}
    x' = y \\
    R(y) \cap (L \setminus \{x_1, x_2, ..., x_n\} ) = \{y\}\\
   \end{array}
  \right.
$$
\end{theorem}
\begin{proof}
//TODO
\end{proof}

\begin{theorem}
Определения LRU через диапазоны вытеснения и через списки
эквивалентны.
\end{theorem}
\begin{proof}
//TODO

Показать, что согласно лемме~\ref{includedranges} можно использовать
$L$ перед концом диапазона.
\end{proof}

\subsubsection{FIFO -- First-In First-Out}

FIFO (First-In First-Out) -- это стратегия вытеснения, определяющая
вытесняемые данные согласно принципу очереди FIFO. ///ГДЕ ИСПОЛЬЗУЕТСЯ???

Стратегия FIFO может быть описана на основе порядка на элементах
набора (т.е. набор представляется списком элементов). После каждой
инструкции элементы переупорядочиваются согласно следующим правилам
(см.рис.~\ref{fifo1}):
\begin{itemize}
\item при кэш-попадании порядок элементов не меняется;
\item при кэш-промахе вытесняется последний элемент, в начало
вставляется элемент, вызвавший промах.
\end{itemize}

\begin{figure}[h] \center
  \includegraphics[width=0.6\textwidth]{fifo1}\\
  \caption{Стратегия вытеснения FIFO (w - ассоциативность кэш-памяти)}\label{fifo1}
\end{figure}

Отличие от LRU лишь в том, что при FIFO не происходит перестановки
элементов набора при возникновении кэш-попадания.

Это поведение может быть записано компактно с использованием
уравнений на множества. Определим диапазоны вытеснения для FIFO как
множество инструкций от внесения адреса в кэш-память до его
вытеснения. Причем исключим из него все инструкции с кэш-попаданиями
(они не играют никакой роли с точки зрения FIFO). Тогда \emph{FIFO
будет выполнено в том случае, когда в диапазоне встречаются все
адреса состояния кэш-памяти перед вытеснением без самого
вытесняемого адреса}.

Запишем в виде уравнений на множества эту логику. Предикат
$displaced(x')$ будет представлен дизъюнкцией уравнений -- каждый
элемент дизъюнкции соответствует некоторому диапазону вытеснения.
Тогда для диапазона вытеснения к инструкции, обращающейся к адресу
$y$ надо составить такую систему уравнений ($x_1, x_2, ..., x_n$ --
множество адресов, к которым происходят обращения внутри диапазона
вытеснения \textbf{с кэш-промахами}, а также элементы начального
состояния, если диапазон начинается там, $L$ -- выражение для
состояния кэш-памяти для инструкции, вытесняющей $x'$):
$$
\left\{
   \begin{array}{l}
    x' = y \\
    \{x_1, x_2, ..., x_n\} \cap R(y) = (L \setminus \{y\}) \cap R(y)\\
   \end{array}
  \right.
$$

Функциональный символ $R$ используется в смысле множества адресов
того же региона.

Для FIFO справедливы все леммы о диапазонах вытеснения,
сформулированные для LRU. В частности, с использованием их система
уравнений для диапазона вытеснения может быть переписана следующим
образом:
$$
\left\{
   \begin{array}{l}
    x' = y \\
    R(y) \cap (L \setminus \{x_1, x_2, ..., x_n\}) = \{y\}\\
   \end{array}
  \right.
$$

\begin{theorem}
Определения FIFO через диапазоны вытеснения и через списки
эквивалентны.
\end{theorem}
\begin{proof}
//TODO

Показать, что согласно лемме~\ref{includedranges} можно использовать
$L$ перед концом диапазона.
\end{proof}

\subsubsection{Pseudo-LRU}

Стратегия вытеснения LRU хоть и хорошо приближает поведение
кэш-памяти к идеальному случаю (когда данные находятся в кэш-памяти
в тот момент, когда они нужны), но для нее не удалось найти
эффективную реализацию. Поэтому производятся поиски стратегии
вытеснения, близкой по качеству к LRU, но имеющей эффективную
реализацию. Эти поиски привели к стратегии вытеснения Pseudo-LRU.
Она определяется только для кэш-памяти с ассоциативностью,
являющейся степенью двойки.

Для каждого набора хранится битовая строка длины $w-1$, где $w$ --
ассоциативность кэш-памяти. Каждая инструкция, обращающаяся к
набору, меняет эту битовую строку. Определение вытесняемого элемента
производится тоже на основании этой битовой строки. Для наглядности
алгоритм изменения битовой строки описывают на упорядоченном
бинарном дереве высоты $\log_2 w$, в листьях которого подряд
расположены элементы набора. Вытесняющий элемент помещается в дереве
на место вытесняемого. Между элементами битовой строки и нелистовыми
элементами установлено взаимнооднозначное соответствие. Каждая дуга
в дереве помечена числом 0 или 1, из каждого нелистового узла
выходят дуги, помеченные разными числами.

При кэш-попадании по некоторому адресу меняются элементы битовой
строки, соответствующие вершинам дерева, которые входят в путь от
корня до этого адреса (см. рис.~\ref{pseudo_lru_hit}). А именно,
элемент битовой строки становится равным пометке дуги, исходящей из
соответствующего ему узла. Остальные элементы битовой строки не
меняются.

\begin{figure}[h] \center
  \includegraphics[width=0.7\textwidth]{plruhit}\\
  \caption{Кэш-попадание для стратегия вытеснения Pseudo-LRU
  (16-ассоциативная кэш-память)}\label{pseudo_lru_hit}
\end{figure}

Поиск вытесняемого элемента производится следующим образом: на
основе значений элементов битовой строки (т.е. нелистовых узлов
дерева) определяется единственный путь. Лист, к которому ведет этот
путь, и является вытесняемым элементом. Путь определяется
итеративно: первая вершина -- всегда корень, из него выбирается
дуга, помеченная значением, противоположным значению элемента
битовой строки, соответствующей корню. Затем эта же операция
повторяется для узла -- конца этой дуги, а именно, выбирается
исходящая из него дуга, пометка которого имеет значение,
противоположное тому, какому этот узел соотнесен в битовой строке.
На место вытесняемого элемента помещается вытесняющий, битовая
строка меняется так, будто к вытесняющему элементу было обращение с
кэш-попаданием. Пример того, как определяется вытесняемый элемент,
показан на рис.~\ref{pseudo_lru_miss}. Цветом нелистовых узлов
показано значение соответствующего им элементов битовой строки:
черный узел соответствует значению 1, белый -- 0. В изображенном
дереве будет выбран путь $\alpha-\gamma-\zeta$, согласно которому
будет вытеснен элемент $e$.

\begin{figure}[h] \center
  \includegraphics[width=0.5\textwidth]{plrumiss}\\
  \caption{Определение вытесняемого элемента для стратегия вытеснения
  Pseudo-LRU (16-ассоциативная кэш-память)}\label{pseudo_lru_miss}
\end{figure}

Иными словами, определение вытесняемого элемента можно проводить,
последовательно рассматривая тестовые ситуации от данной инструкции
с кэш-промахом назад к первой инструкции. Каждая очередная
инструкция отсекает то поддерево, которому принадлежит адрес в этой
инструкции (если адрес принадлежит уже отсеченной части дерева,
инструкция игнорируется). В результате, на некотором шаге останется
дерево из одного элемента, вытесняемый элемент и будет тем самым
элементом.

В качестве диапазона вытеснения (следуя эвристике непересекающихся
шаблонов) выберем последовательность инструкций от последнего
обращения к элементу набора, находящимся в той же паре (т.е.
имеющего того же непосредственного предка в дереве), что и
вытесняемый элемент.

\paragraph{Pseudo-LRU для 4-х-ассоциативной кэш-память}

Для 4-х-ассоциативной кэш-памяти предлагается следующая схема
построения уравнений, описывающая вытесняемый элемент. Несмотря на
кажущуюся очевидность этого случая, 4-х-ассоциативная Pseudo-LRU
кэш-память активно используется в микропроцессорах.

Содержимое кэш-памяти вновь представляется множеством адресов данных
$L$, которые в ней хранятся. Но теперь к каждой инструкции будет
добавлено 3 новых переменных:
\begin{itemize}
\item $h_i \in \{0, 1\}$ задает пару, которой принадлежит адрес в
данной инструкции; в 4-х-ассоциативной кэш-памяти 2 пары, одна
кодируется значением 1, другая -- значением 0;
\item $H'_i$ -- множество элементов кэш-памяти, принадлежащих паре с
$h = 0$; $H'_i \subseteq L$;
\item $H''_i$ -- множество элементов кэш-памяти, принадлежащих паре с
$h = 1$;  $H''_i \subseteq L$.
\end{itemize}

Для каждой инструкции выполнены тождества $H''_i \cap H'_i =
\varnothing, H''_i \cup H'_i = L_i$, где $L_i$ -- содержимое
кэш-памяти перед $i$-й инструкцией.

Для кэш-попадания $hit(v_i)$ выделяются следующие ограничения:

$$
\left\{
   \begin{array}{l}
    v_i \in L_i \\
    v_i \in H'_i \rightarrow h_i = 0 \\
    v_i \in H''_i \rightarrow h_i = 1 \\
    H'_{i+1} \equiv H'_i \\
    H''_{i+1} \equiv H''_i \\
    L_{i+1} \equiv L_i
   \end{array}
  \right.
$$

Для кэш-промаха $miss(v_i)$ с вытеснением элемента $v^{\delta}_i$
следующие ограничения:

$$
\left\{
   \begin{array}{l}
    v_i \notin L_i \\
    v^{\delta}_i \notin L_i \\
    R(v_i) = R(v^{\delta}_i) \\
    h_i = 0 \rightarrow v^{\delta}_i \in H'_i \wedge H''_{i+1} \equiv
    H''_i \wedge H'_{i+1} \equiv H'_i \setminus \{v^{\delta}_i\} \cup
    \{v_i\}\\
    h_i = 1 \rightarrow v^{\delta}_i \in H''_i \wedge H'_{i+1} \equiv
    H'_i \wedge H''_{i+1} \equiv H''_i \setminus \{v^{\delta}_i\} \cup
    \{v_i\}\\
    L_{i+1} \equiv L_i \setminus \{v^{\delta}_i\} \cup \{v_i\}\\
    displaced(v^{\delta}_i)
   \end{array}
  \right.
$$

Предикат $displaced(v^{\delta}_i)$ представляется дизъюнкцией
систем, каждая из которых описывает диапазон вытеснения. Для каждого
диапазона вытеснения, начинающегося на инструкции с адресом данных
$v_j$ составляется следующая система:

$$
\left\{
   \begin{array}{l}
    v^{\delta}_i \neq v_j \\
    R(v_i) = R(v_j) \\
    h_i = h_j \\
    h_i \notin \{ h_{j+1}, h_{j+2}, ..., h_{i-1} \} \\
    v_j \notin \{ v_{j+1}, v_{j+2}, ..., v_{i-1} \} \\
   \end{array}
  \right.
$$

Получается система ограничений от переменных $\{v_i\}, \{h_i\}, L_0,
H'_0$ ($H''_0 \equiv L_0 \setminus H'_0$).

\begin{theorem}
Ограничения определяют элемент, являющийся вытесняемым согласно
определению через бинарное дерево.
\end{theorem}
\begin{proof}
//TODO (почти очевидно)
\end{proof}

\paragraph{Pseudo-LRU для кэш-памяти произвольной ассоциативности}
В общем случае, однако, предъявленная схема, примененная к
кэш-памяти большей ассоциативности, дает системы ограничений гораздо
большего размера. Поэтому для кэш-памяти произвольной
ассоциативности предлагается следующий способ генерирования системы
ограничений.

Для простоты рассмотрим случай полностью ассоциативной кэш-памяти,
случай наборно-ассоциативной кэш-памяти лишь технически сложнее,
поскольку в некоторые места надо добавить ограничение совпадения
региона с регионом вытесняющего адреса.

Для каждой инструкции введем новую переменную $p_i$
(\emph{<<характеристику>>}) -- битовая строка длины $\log_2 w$ (по
сути -- номер элемента в наборе). Диапазон вытеснения выбирается так
же -- к элементу той же пары, что и вытесняемый элемент. Предикат
$displaced$ составляется как дизъюнкция систем для каждого диапазона
вытеснения. Пусть $p$ -- характеристика вытесняющего элемента. Она
равна характеристике вытесняющего элемента. Пусть $p'$ --
характеристика начала диапазона вытеснения, $p_1, p_2, ..., p_n$ --
характеристики адресов внутри диапазона от конца к началу. Пусть
$q_i \equiv p_i \oplus p$, $q' \equiv p' \oplus p$. Пусть $A(x,y)
\equiv (x\gg2)\geqslant y \vee (x\gg1) > y \wedge ((x \gg 1) \oplus
y)> y \wedge ((x \gg 2) \oplus y) < y$ (операция $\oplus$ возвращает
побитовую сумму по модулю 2 двух битовых строк одинаковой длины).
Пусть $W \equiv \log_2 w$.

Тогда для этого диапазона вытеснения нужно генерировать следующую
систему уравнений:

$$
\left\{
   \begin{array}{l}
    q' = 1 \\
    q_1 \gg (W-1) = 1 \\
    p \notin \{p_1, p_2, ..., p_n\}\\
    p' \notin \{p_1, p_2, ..., p_n\}\\
    v^{\delta} \neq v'\\
    p_{v^{\delta}} = p\\
    \{q_1, q_2, ..., q_n\} \cap [2^0, 2^1) \neq \varnothing\\
    \{q_1, q_2, ..., q_n\} \cap [2^1, 2^2) \neq \varnothing\\
    ...\\
    \{q_1, q_2, ..., q_n\} \cap [2^{W-1}, 2^W) \neq \varnothing\\
    \forall q_i,q_j (j > i \wedge q_i > q_j \wedge A(q_i,q_j) \rightarrow
    \exists q_k (j > k \wedge k > i \wedge \neg A(q_i,q_k)))\\
   \end{array}
  \right.
$$

Кванторы можно расписать в дизъюнкции и конъюнкции по элементам
диапазона вытеснения. Неформально говоря, уравнения отражают
следующие свойства диапазона вытеснения:
\begin{enumerate}
\item первое ограничение означает, что конец и начало диапазона
принадлежат одной паре и не равны;
\item второе ограничение означает, что адрес в ближайшей к концу
диапазона вытеснения инструкции и адрес в инструкции--конце
диапазона должны принадлежать разным поддеревьям бинарного дерева;
\item следующие два ограничения означают, что к адресам в инструкции-начале
диапазона и инструкции-конце диапазона производится последнее
обращение перед вытеснением;
\item следующий блок ограничений описывает свойство полноты
диапазона вытеснения: в нем должны встретиться инструкции из всех
тех поддеревьев, которые влияют на вытеснение нужного элемента;
\item и последнее ограничение описывает свойство порядка --
обращения к поддеревья должны встретиться в таком порядке, который
приводит к вытеснению нужного элемента, а именно, если за обращением
к одному поддереву следует обращение к другому поддереву, между
которыми может быть еще одно поддерево, то между ними должно быть
обращение к этому поддереву (см. рис.~\ref{plru}); $A(x,y)$ истинна
для ненулевых $x$ и $y$, причем $x > y$, если префикс из нулей в
числе $x$ длиннее как минимум на 2 префикса из нулей в числе $y$.
\end{enumerate}

\begin{figure}[h] \center
  \includegraphics[width=0.8\textwidth]{plru}\\
  \caption{Для вытеснения $a$ нужно, чтобы в диапазоне вытеснения между обращениями в поддеревья с
  корнями в $\gamma$ и $\iota$ было обращение в поддерево с корнем в $\varepsilon$}\label{plru}
\end{figure}

% как вариант первого ограничения: \exists a, b : a перед b, q_a < q_b \rightarrow
% \exists c перед a : q_c >> (W-1) = q_b >> (W-1)
% иными словами, если есть пара в неправильном порядке, то перед первым
% ее элементом есть другой, что он с первым образует правильный порядок

//TODO как изменятся ограничения, если $p' \in L_0$ ??

\begin{theorem}
Ограничения определяют элемент, являющийся вытесняемым согласно
определению через бинарное дерево.
\end{theorem}
\begin{proof}
//TODO
\end{proof}


\pagebreak
\section{Разрешение уравнений, описывающих тестовые ситуации в
кэш-памяти; вопросы эффективности}

\begin{abstract}
В разделе рассматриваются два типа алгоритмов генерации тестовых
данных: один требует огромной и нетривиальной работы над задачей
разрешения специальных ограничений, а другой (предлагаемый) пытается
эффективно использовать имеющиеся решатели для генерации тестовых
данных. Достоинством предлагаемого алгоритма является снижение
сложности подготовки генератора тестовых данных за счет рассмотрения
наиболее часто использующихся механизмов работы с памятью (а именно,
ограничения строятся \emph{совместно} для кэш-памяти и TLB).
Дополнительно раздел дает информацию о типах программ-solver'ов и
эвристик выбора тех или иных в зависимости от решаемой задачи.
Предложенное разделение задачи генерации тестовых данных по уровням
является еще одним новым результатом.
\end{abstract}

Введение: что такое TLB.

\subsection{Особенности исполнения инструкций обращения к памяти
на современных микропроцессорах}

В инструкции обращения к памяти в современных микропроцессорах
задействована не одна подсистема. Исполнение инструкции обращения к
памяти можно разбить на два этапа -- подготовка физического адреса и
собственно обращение с памятью (см.рис.~\ref{memoryAccess}).

\begin{figure}[h] \center
  \includegraphics[width=0.5\textwidth]{instr}\\
  \caption{Модель исполнения инструкции обращения к памяти}\label{memoryAccess}
\end{figure}

Подготовка физического адреса включает в себя формирование
виртуального адреса данных, с которыми необходимо выполнить
операцию. Виртуальный адрес формируется на основе аргументов
инстркции. Затем происходит формирование физического адреса на
основе виртуального адреса с использованием TLB. По сути виртуальный
адрес разбивается на номер виртуальной страницы и смещение внутри
страницы, затем, используя TLB, физический адрес составляется из
соответствующего номера физического кадра и того же смещения внутри
страницы. TLB содержит некоторое количество пар, задающих
соответствие номера страницы виртуальной памяти и физического кадра.
Размер самой страницы в виртуальной памяти и физической памяти
совпадает, поэтому смещение внутри страницы используется в
физическом адресе без изменений по сравнению с виртуальным адресом.

Когда физический адрес готов, осуществляется обращение с памятью:
загрузка данных из памяти или сохранение данных в памяти. При этом
если данные по физическому адресу имеются в кэш-памяти, основная
память может остаться неизмененной. Это сделано для повышения
эффективности работы с основной памятью.

//////////////TODO зачем нужно было применять такие сложные вещи? может быть,
20\% труда сделает 80\% работы (обычным рандомом), а в оставшемся
небольшом остатке работы надо действовать более интеллектуально (а
если вероятность (отношение количества тестовых данных к количеству
значений в их области определения) не мала, то прагматический вопрос
стоит очень остро); другой момент - \textbf{у Genesys-Pro очень
много положительных моментов} и самый главный -- масштабируемость,
напротив моё решение плохо масштабируемо, значит, надо искать
критерий, по которому мое решение лучше... Если бы не цена
Genesys-Pro, стоило ли делать эту работу?

\subsection{Уровни генерации тестовых данных}

Задача может быть представлена в нескольких формах в зависимости от того, что требуется найти:
\begin{itemize}
\item \emph{простая форма:} найти начальное состояние
микропроцессора (а именно, содержимое кэш-памяти, TLB и других
подсистем и значения регистров); тогда кроме задачи поиска тестовых
данных возникает задача достижения построенного начального состояния
микропроцессора, исходя из состояния микропроцессора перед
тестированием (\emph{проблема генерации инициализирующей
программы}); построенные инструкции инициализации должны быть
помещены перед инструкциями тестового шаблона; проблема в том, что
сами инструкции инициализации микропроцессора могут быть исполнены
некорректно и тогда на инструкциях тестового шаблона либо могут не
проявиться ошибки, либо появиться ложные ошибки;
\item \emph{минимальная форма:} найти лишь значения регистров, используя
данное начальное состояние (содержимое) кэш-памяти, TLB и других
подсистем; в отличие от предыдущей формы здесь само тестирование
кэш-памяти будет проводиться без внесения возможных дополнительных
ошибок от инициализирующей программы, но в такой форме задача не
всегда разрешима;
\item \emph{смешанная форма:} требуется построить
значения регистров и последовательность инструкций инициализации
состояния микропроцессора небольшого размера; в такой форме
увеличивается сложность задачи, потому что невозможно заранее
предугадать, сколько необходимо и достаточно дополнительных
инструкций.
\end{itemize}

Задачу поиска тестовых данных в минимальной форме будем называть
задачей генерации тестовых данных \emph{нулевого уровня}. Дальнейшие
уровни определяются возможностью изменять кэш-память и другие
подсистемы разными инструкциями. Например, для архитектуры
MIPS~\cite{mips64_II} были выделены следующие уровни генерации
тестовых данных помимо нулевого уровня:
\begin{itemize}
\item на \emph{первом уровне} разрешается менять те строки TLB,
которые не кэшированы в буфере TLB; изменение одной строки можно
делать независимо от остальных строк и буфера одной инструкцией
(TLBWI);
\item на \emph{втором уровне} разрешается менять любую строку TLB;
при этом кроме смены строк, не входящих в буфер TLB, нужно
переинициализировать содержимое буфера (на каждую строку отдельная
инструкция);
\item на \emph{третьем уровне} разрешается менять и TLB, и кэш-память.
\end{itemize}

Чем больше уровень, тем длиннее будет инициализирующая программа и тем сложнее ее построить.

\subsection{Модульный алгоритм генерации тестовых данных}

На основе представленной модели инструкции обращения к памяти можно
составить ограничения для каждого шага, получив тем самым
\emph{модульный алгоритм} генерации тестовых данных. Более
формально, пусть $\{(I_i, R_i, \{As\}_i, C_i, T_i)\}_{i=1, 2, ...,
n}$ -- тестовый шаблон, $\{I_i\}_{i=1, 2, ..., n}$ --
последовательность инструкций, $R_i$ -- регистр с данными,
$\{As\}_i$ -- параметры инструкции, задающие адрес в памяти,
$\{C_i\}_{i=1, 2, ..., n}$ -- последовательность тестовых ситуаций в
кэш-памяти, $\{T_i\}_{i=1, 2, ..., n}$ -- последовательность
тестовых ситуаций в TLB. Поскольку TLB может содержать
дополнительные буфера, ведущие себя как кэш-память, то в TLB также
возможны кэш-попадания и кэш-промахи. Тогда инструкция может быть
представлена в виде следующих уравнений для каждого $i$:
$$
\left\{
   \begin{array}{l}
    v_i = CalculateVirtualAddress(\{As\}_i) \\
    AddressTranslation(T_i,~p_i,~v_i,~TLB_0,~\{v_1,...,v_{i-1}\})\\
    CacheAccess(C_i,~p_i,~L_0,~\{p_1,...,p_{i-1}\})\\
    MemoryAccess(I_i,~R_i,~p_i,~\{p_1,...,p_{i-1}\},~\{R_1,...,R_{i-1}\})\\
   \end{array}
  \right.
$$
где $v_i$ и $p_i$ -- новые переменные, $TLB_0$ -- начальное
состояние (содержимое) TLB, $L_0$ -- начальное состояние
(содержимое) кэш-памяти, $CalculateVirtualAddress$ -- функция,
вычисляющая виртуальный адрес на основе аргументов инструкции.
$AddressTranslation$ -- предикат, описывающий трансляцию
виртуального адреса в физический (здесь может быть задействован
TLB). $CacheAccess, MemoryAccess$ -- предикаты, описывающие
обращение в память (в первом может быть задействована кэш-память, во
втором -- основная память).

Поскольку система уравнений для тестового шаблона составляется как
конъюнкция систем для каждой инструкции, то система из предикатов
может быть выделена в отдельные подзадачи (в этом проявляется
модульность). Таким образом выделяются следующие подзадачи:
\begin{itemize}
\item \emph{задача на TLB}
$$
\left\{
   \begin{array}{l}
    AddressTranslation(T_1,~p_1,~v_1,~TLB_0,~\varnothing)\\
    AddressTranslation(T_2,~p_2,~v_2,~TLB_0,~\{v_1\})\\
    ...\\
    AddressTranslation(T_n,~p_n,~v_n,~TLB_0,~\{v_1, ..., v_{n-1}\})\\
   \end{array}
  \right.
$$
\item \emph{задача на кэш-память}
$$
\left\{
   \begin{array}{l}
    CacheAccess(C_1, p_1, L_0, \varnothing)\\
    CacheAccess(C_2, p_2, L_0, \{p_1\})\\
    ...\\
    CacheAccess(C_n, p_n, L_0, \{p_1, ..., p_{n-1}\})\\
   \end{array}
  \right.
$$
\item \emph{задача на основную память}
$$
\left\{
   \begin{array}{l}
    MemoryAccess(I_1,~R_1,~p_1,~\varnothing, \varnothing)\\
    MemoryAccess(I_2,~R_2,~p_2,~\{p_1\}, \{R_1\})\\
    ...\\
    MemoryAccess(I_n,~R_n,~p_n,~\{p_1, ..., p_{n-1}\}, \{R_1, ..., R_{n-1}\})\\
   \end{array}
  \right.
$$
\end{itemize}

Как раз задаче на кэш-память был посвящен раздел~\ref{cache_sets}. В
нем было показано, что для этой задачи достаточно ввести переменную
с начальным содержимым кэш-памяти. Для выделения тегов адресов и
номеров набора (например, в наборно-ассоциавной кэш-памяти) в
ограничениях могут потребоваться битовые операции. Например, если
тег определяется как старшие биты физического адреса, то потребуется
уравнение вида $tag_i = physical[N..M]$, где $N$ и $M$ -- границы
битового поля <<тег>> физического адреса.

Задача на основную память задает соответствие между значениями
регистров, физическими адресами и значениями ячеек оперативной
памяти. Если представить основную память в виде одномерного массива
$memory$, индексация в котором идет по физическим адресам, то
\begin{itemize}
\item для инструкции, осуществляющей загрузку из памяти,
$MemoryAccess$ можно представлять как $R_i :=
memory[physicalAddress_i]$;
\item для инструкции, осуществляющей сохранение в памяти,
$MemoryAccess$ можно представлять как $memory[physicalAddress_i] :=
R_i$.
\end{itemize}
Таким образом, получается последовательность присваиваний, которая
может быть преобразована в систему уравнений с помощью
\emph{редукции Аккермана} (или
\emph{аккерманизации})~\cite{Ackermann}. А именно,
\begin{itemize}
\item для каждой упорядоченной пары инструкций (не обязательно
находящиеся подряд в тестовом шаблоне, но в том же порядке)
$STORE(R_1, p_1)$ и $LOAD(R_2, p_2)$ создается ограничение $$ (p_1 =
p_2 \wedge p_2 \notin \{ p_{(1)}, p_{(2)}, ..., p_{(k)}\})
\rightarrow R_1 = R_2$$ где $p_{(1)}, p_{(2)}, ..., p_{(k)}$ --
физические адреса инструкций $STORE$, расположенных между двумя
инструкциями этой пары;
\item для каждой упорядоченной пары инструкций (не обязательно
находящиеся подряд в тестовом шаблоне, но в том же порядке)
$LOAD(R_1, p_1)$ и $LOAD(R_2, p_2)$ создается ограничение $$ (p_1 =
p_2 \wedge p_2 \notin \{ p_{(1)}, p_{(2)}, ..., p_{(k)}\})
\rightarrow R_1 = R_2$$ где $p_{(1)}, p_{(2)}, ..., p_{(k)}$ --
физические адреса инструкций $STORE$, расположенных между двумя
инструкциями этой пары.
\end{itemize}

Задача на TLB должна задавать в виде ограничений соответствие между
начальным состоянием (содержимым) TLB, виртуальными адресами,
физическими адресами и вносимыми в TLB соответствиями в случае
промаха. Поскольку содержимое TLB также может быть рассмотрено в
виде массива записей, то для задачи на TLB тоже применима
аккерманизация. Кроме того, здесь также могут быть использованы
методы построения уравнений на множества тегов для описания тестовых
ситуаций на буферы, которые ведут себя как кэш-память, если таковые
присутствуют в TLB.

Для разрешения полученных ограничений применяется решатель CSP
(Constraint Satisfaction Problem)~\cite{CSP}. Сначала надо дать
определение, что такое CSP. Пусть $X = \{x_1, x_2, ..., x_n\}$ --
множество переменных (для каждой переменной известна область
определения -- обычно это конечное множество или ограниченный
интервал). CSP состоит из предикатов (\emph{ограничений}) $C(y_1,
y_2, ..., y_N)$, где $y_i \in X$ (см. рис.~\ref{csp}).

\begin{figure}[h] \center
  \includegraphics[width=0.5\textwidth]{csp}\\
  \caption{Constraint Satisfaction Problem}\label{csp}
\end{figure}

Решение задачи заключается в поиске значений переменных из областей
определения, на которых выполнены все предикаты. Основной методикой
решения CSP является \emph{constraint propagation}, а именно
итеративное построение новых ограничений на основе данного в задаче
множества ограничений (логических следствий). Если в процессе
constraint propagation будет построено тождественно ложное
ограничение, то CSP считается \emph{несовместной}. Иными словами,
для ее переменных не существует значений, при которых выполнены все
ограничения. Особо обращается внимание на одноместные ограничения,
поскольку с помощью них уменьшается область определения переменной.
Если constraint propagation не привел к тождественно ложному
ограничению, то если области определения уменьшены до единственного
значения, то это значение и будет ответом. Если же в области
определения всё ещё много значений, то для выбора из области
определения используются различные техники перебора
(последовательный перебор, перебор в случайном порядке, метод ветвей
и границ). Эвристические алгоритмы решения CSP обычно чередуют этапы
перебора значений и constraint propagation. Одними из таких
алгоритмов являются алгоритмы семейства MAC (Maintaining Arc
Consistency)~\cite{CSP}. Одним из важных направлений развития CSP
стала интеграция с парадигмой логического программирования --
результат этого слияния именуют CLP (Constraint Logic
Programming)~\cite{CLPusingECLiPSe}. Примеры систем CLP -- SICStus
Prolog~\cite{SICStus}, ILOG~\cite{ILOG},
ECLiPSe~\cite{CLPusingECLiPSe}.

Достоинством модульного алгоритма является простота построения
ограничений. Другим достоинством является его гибкость по отношению
к механизмам работы подсистем микропроцессора. Эти свойства успешно
использованы в инструменте Genesys-Pro~\cite{GenesysPro} от компании
IBM. Цель инструмента -- генерация тестовых программ по данным
тестовым шаблонам. Тестовые шаблоны позволяют задать инструкции
тестовой программы, ограничения на их аргументы и некоторые
параметры генерации аргументов. Тестовые программы строятся
итеративно по одной инструкции. А именно цель одного шага --
сгенерировать аргументы для очередной инструкции. Для этого на
основе аргументов инструкции и модели состояния микропроцессора
перед инструкцией составляется CSP, описывающая тестовую ситуацию.
Если эта CSP совместна, она разрешается с получением аргументов
инструкции, инструкция с построенными аргументами исполняется,
фиксируется состояние микропроцессора после этого и генерация
продолжается со следующей инструкции. Если эта CSP несовместна,
происходит возврат к предыдущей инструкции с целью сгенерировать для
нее другие аргументы. Тестовый шаблон может содержать указание
эвристики для выбора значения для переменной в ее области
определения. Кроме того тестовые шаблоны могут содержать указания
повторить некоторую последовательности инструкции некоторое
количество раз. Для тестирования механизмов трансляции этот
инструмент содержит специальный генератор ограничений
DeepTrans~\cite{DeepTrans}. Эффективность генерации тестовых
программ падает с усложнением тестовых шаблонов. В крайнем случае
вместо эффективного constraint propagation инструмент будет
перебирать всевозможные начальные состояния микропроцессора, пока не
подберется допустимый тестовым шаблоном.

Модульный алгоритм требует продвинутый решатель CSP, заточенный под
особенности генерации тестовых данных для тестовых шаблонов (как
минимум такие ограничения могут включать битовые операции). Подобный
решатель был разработан в IBM для инструмента
Genesys-Pro~\cite{GenesysSolver}. Создание такого решателя --
отдельное сложное исследование, которое не входило в цели данного
исследования. В данной работе было принято решение использовать
доступные существующие решатели (не обязательно CSP), а
сосредоточиться на упрощении генерируемых ограничений для некоторых
частных случаев архитектур. Кроме наличия битовых операций,
ограничения усложняются за счет огромных областей определения и
размерности переменных. Например, кэш-память может содержать порядка
$10^4-10^5$ тегов -- такие размерности могут вылиться в
невозможность даже просто хранить в памяти ограничения на такое
большое количество переменных.

\subsection{Немодульный алгоритм генерации тестовых данных: уровень 0}

В рамках проводимого исследования был предложен иной алгоритм, не
являющийся модульным, но не требующий сложной творческой работы по
выработке алгоритма решения ограничений. Немодульность предлагаемого
алгоритма заключается в том, что ограничения строятся не для каждого
этапа исполнения инструкции (трансляция адреса, обращение в
кэш-память), а для всей инструкции целиком. Это позволяет эффективно
использовать известные начальные состояния кэш-памяти и TLB и
строить существенно более компактную систему ограничений, но для
каждой новой архитектуры приходится формулировать алгоритм
построения ограничений заново, но основываясь на общих идеях.
Поэтому, наверное, более точно было бы назвать это не алгоритмом, а
методикой, но в данном разделе речь пойдет об алгоритмической части,
а методическая будет рассмотрена в следующих разделах.

Начинается построение тестовых данных, как уже привычно, с
формулирования исполнения инструкции обращения в память в виде
уравнений. Рассмотрим следующее модельное исполнение инструкции
обращения к памяти. Оно близко к исполнению инструкция обращения к
памяти в архитектуре MIPS~\cite{mips64_III}. (легенда
обозначений!!!!)

$$
\left\{
   \begin{array}{l}
    \widehat{v} = CalculateVirtualAddress(\widehat{\{As\}}) \\
    \widehat{Mapped} = isMapped(\widehat{v})\\
    (\widehat{Mapped} \rightarrow \\
    \quad  \widehat{T}~=~TLBHit~\wedge\\
    \quad  \widehat{vpn} = \widehat{v}_{vpnbits}~\wedge\\
    \quad  \widehat{pfn} = TLB[\widehat{vpn}].pfn~\wedge\\
    \quad  \widehat{Cached} = TLB[\widehat{vpn}].cca~\wedge\\
    \quad  \widehat{p} = \widehat{pfn}||\widehat{v}_{pageoffset}~\wedge\\
    \quad  TLBSituation( \widehat{T}, TLB[\widehat{vpn}], TLB_0 ) )\\
    ( \neg \widehat{Mapped} \rightarrow \\
    \quad  \widehat{p} = CalculatePhysicalAddress(\widehat{v})~\wedge\\
    \quad  \widehat{Cached} = isCached(\widehat{v}) )\\
    ( \widehat{Cached} \rightarrow\\
    \quad  \widehat{tag_{L1}} = \widehat{p}_{tagbits~in~L1}~\wedge\\
    \quad  \widehat{set_{L1}} = \widehat{p}_{setbits~in~L1}~\wedge\\
    \quad  CacheSituation( \widehat{C}, \widehat{tag_{L1}}, \widehat{set_{L1}}, L_0 ))\\
    MemoryAccess(I_i,~R_i,~p_i,~\{p_1,...,p_{i-1}\},~\{R_1,...,R_{i-1}\})\\
   \end{array}
  \right.
$$

$CacheSituation$ (кэш-попадание или кэш-промах) и $TLBSituation$
будут выписаны в виде ограничений с использованием множеств тегов
(см. раздел~\ref{cache_sets}). Затем эти ограничения будут поданы на
вход решателю. Если уравнения на множества не поддерживаются
решателем (а это стандартная ситуация), то эти уравнения могут быть
преобразованы в предикаты на равенства и неравенства элементов,
входящих во множества, а именно ограничение вида $x \in \{a, b, ...,
c\}$ преобразовано в $(x = a \vee x = b \vee ... \vee x = c)$, а
ограничение вида $x \notin \{a, b, ..., c\}$ -- в $(x \neq a \wedge
x \neq b \wedge ... \wedge x \neq c)$.

Однако уравнения для $CacheSituation$ содержит начальное состояние
кэш-памяти $L_0$ ($tag \in L_0$ или $tag \notin L_0$), которое имеет
большой размер. Тем самым при преобразовании в равенства и
неравенства будет получена формула большой длины. Ситуация
ухудшается еще и тем, что общедоступные решатели ограничений не
позволяют работать формулами такой длины. Для $TLBSituation$ эта
проблема не так актуальна, поскольку размер TLB небольшой и
позволяет явное выписывание своего содержимого в формуле.

Теорема~\ref{hit_miss_equations} дает дизъюнктивную форму уравнений
на множества тегов, описывающих тестовые ситуации в кэш-памяти (в
широком смысле). Проблема длинной формулы возникает в том случае,
когда в формулу из дизъюнктивной формы попадает подформула, которая
содержит элементы начального состояния микропроцессора. А именно,
для кэш-попадания это подформула $$x \in L_0 \wedge x \notin \{x'_1,
x'_2, ..., x'_n\},$$ для вытесняющего тега -- подформула $$x \notin
L_0 \wedge x \notin \{x_1, x_2, ..., x_n\},$$ для вытесняемого тега
две подформулы -- одна как для тега кэш-попадания, а вторая предикат
$displaced$ (например, для LRU он содержит подформулу $$R(y) \cap
(L_{current} \setminus A ) = \{y\},$$ где $L_{current}$ -- текущее
состояние кэш-памяти и может быть представлено в виде формулы,
зависящей от $L_0$ так, как это дается в лемме~\ref{L_current}, а
$A$ -- множество тегов, расположенных внутри диапазона вытеснения --
оно также может затрагивать $L_0$). Все остальные случаи могут быть
выписаны явно в конъюнкцию -- они длинных формул не дают. Поэтому
далее рассмотрение будет вестись именно представленных здесь
подформул.

Из представленной системы можно выделить 4 случая (они описывают
свойство виртуального адреса, которое может пониматься как сегмент
виртуальной памяти): $Mapped \wedge Cached$, $Mapped \wedge \neg
Cached$, $\neg Mapped \wedge Cached$ и $\neg Mapped \wedge \neg
Cached$ -- и далее будет представлен новый алгоритм, позволяющий
избежать выписывания всего содержимого кэш-памяти, а учесть лишь
необходимую небольшую его часть.

// где ограничения метода ?

\subsubsection{unMapped-unCached и Mapped-unCached случаи}

В этих случаях размер формулы будет обозримым, поэтому особых упрощений формулы делать не нужно.

\subsubsection{Mapped-Cached случай}

Итак, система ограничений содержит следующее ограничение:
$CacheSituation \wedge TLBSituation$. Вместо того, чтобы выписывать
каждый элемент конъюнкции отдельно, предлагается генерировать
ограничения \emph{сразу для конъюнкции} (в этом проявляется
немодульность алгоритма). Это позволяет существенно сократить размер
получающихся ограничений. В разделе~\ref{cache_sets} описан алгоритм
генерации ограничений для тестовых ситуаций в кэш-памяти с
использованием уравнений на конечные множества тегов.
<<Кэш-памятью>> в широком смысле является и собственно кэш-память --
подсистема микропроцессора -- ее тегами являются битовые поля
физического адреса данных -- и буфер TLB -- в нем тегом является
номер строки TLB. Кажется, что свести воедино номера строк TLB и
битовые поля физического адреса невозможно. Однако строка TLB
содержит номер физического кадра (\emph{PFN, Physical Frame
Number}), который становится частью того битового поля физического
адреса, что является тегом кэш-памяти (см. рис.~\ref{pfn_tagsets}).

\begin{figure}[h] \center
  \includegraphics[width=0.5\textwidth]{pfnts}\\
  \caption{PFN является битовым полем физического адреса}\label{pfn_tagsets}
\end{figure}

Но битовое поле физического адреса, соответствующее PFN, может как
полностью включать в себя битовое поле тег (и при этом включать
часть битового поля сет), так и включать часть битового поля тег.
Однако всегда битовое поле PFN является частью битового поля
\emph{тегсет} -- будем этим термином называть конкатенацию тега и
сета (в этом порядке). Осталось переформулировать тестовые ситуации
на кэш-память и на буфер TLB в виде уравнений на множества PFN и
тегсетов. Множества из констант PFN и множества из констант тегсетов
(например, из начального состояния TLB и начального состояния
кэш-памяти) тем самым можно пересекать, в результате чего получается
множество констант (битовая длина константы этого множества есть
битовая длина тегсета) небольшого размера. На этой идее основано
сокращение размера формулы при рассмотрении конъюнкции тестовых
ситуаций.

Итак, рассмотрим все случаи этой конъюнкции и покажем, как для них строить
ограничения. Введем следующие обозначения:
\begin{itemize}
\item пусть $X$ -- множество констант PFN (т.е. множество битовых
строк, битовая длина каждой из которых равна длине PFN), тогда $[X]
= \{x||y | x \in X \wedge bitlen(x||y) = tagset~bitlen\}$; иными
словами, в качестве $[X]$ будем обозначать множество всевозможных
тегсетов, старшие биты которых являются PFN'ами из заданного
множества $X$;
\item пусть $x$ -- тегсет, тогда $\widehat{x}$ -- битовое поле
соответствующее PFN в тегсете $x$, т.е. $\exists y :
(\widehat{x}||y) = x$;
\item пусть $X$ -- множество констант тегсетов (т.е. множество
битовых строк, битовая длина каждой из которых равна длине тегсета),
тогда $\widehat{X} = \{\widehat{x} | x \in X\}$; иными словами, в
качестве $\widehat{X}$ будем обозначать множество всевозможных PFN,
которые соответствуют тегсетам из заданного множества $X$.
\end{itemize}

Некоторые обозначения для начального состояния микропроцессора (оно
должно быть известно для генерации тестовых данных):
\begin{itemize}
\item $L$ -- множество тегсетов кэш-памяти;
\item $PFN$ -- множество PFN строк TLB;
\item $M$ -- множество PFN строк TLB, входящих в буфер TLB.
\end{itemize}

Аргументы $CacheSituation(V, С, L)$ означают:
\begin{itemize}
\item $V$ -- тегсет физического адреса данных в инструкции, к
которой относится эта тестовая ситуация;
\item $С$ -- тестовая ситуация на кэш-память; значения этой
переменной: $l1Hit$ (кэш-попадание), $l1Miss$ (кэш-промах);
\item $L$ -- множество тегсетов кэш-памяти.
\end{itemize}

Аргументы $TLBSituation(V, T, PFN, M)$ означают:
\begin{itemize}
\item $V$ -- тегсет физического адреса данных в инструкции, к
которой относится эта тестовая ситуация;
\item $T$ -- тестовая ситуация на буфер TLB; значения этой
переменной: $mtlbHit$ (кэш-попадание), $mtlbMiss$ (кэш-промах);
\item $PFN$ -- множество PFN строк TLB;
\item $M$ -- множество PFN строк TLB, входящих в буфер TLB.
\end{itemize}

$CacheSituation(x, l1Hit, L) \wedge TLBSituation(x,
mtlbHit, PFN, M)$:

$$
\left\{
   \begin{array}{l}
    x \in L \cap [M]\\
    x \notin \{ x'_1, x'_2, ..., x'_n \}\\
    \widehat{x} \notin \{ \widehat{t'_1}, \widehat{t'_2}, ..., \widehat{t'_k} \}\\
   \end{array}
  \right.
$$

$\{x'_1, x'_2, ..., x'_n\}$ -- множество вытесняемых тегсетов
инструкций тестового шаблона, расположенных перед данной
инструкцией; $\{\widehat{t'_1}, \widehat{t'_2}, ..., \widehat{t'_k}
\}$ -- множество вытесняемых PFN'в инструкций тестового шаблона,
расположенных перед данной инструкцией. Напоминаю, что это лишь
подформула формулы для $l1Hit$, но остальная часть этой формулы
может быть выписана в конъюнкции явно.

Если $L \cap [M] = \varnothing$, то эта система несовместна. Если
все такие системы, описывающие данную инструкцию, будут несовместны,
то \emph{задача поиска тестовых данных нулевого уровня для данного
тестового шаблона несовместна}, иными словами без изменения
кэш-памяти или буфера TLB для этого тестового шаблона невозможно
подобрать тестовые данные. Т.е. даже не решая еще задачи
выполнимости для формулы еще на этапе ее построения, можно быстро
узнать, совместна ли она. Это еще одно преимущество предлагаемого
алгоритма.

$CacheSituation(x, l1Miss, L) \wedge TLBSituation(x, mtlbHit, PFN,
M)$:

Для вытесняющего тега:

$$
\left\{
   \begin{array}{l}
    x \notin L \cap [M]\\
    x \notin \{ x_1, x_2, ..., x_n \}\\
    \widehat{x} \notin \{ \widehat{t'_1}, \widehat{t'_2}, ..., \widehat{t'_k} \}\\
   \end{array}
  \right.
$$

$\{x_1, x_2, ..., x_n\}$ -- множество вытесняюших тегсетов
инструкций тестового шаблона, расположенных перед данной
инструкцией; $\{\widehat{t'_1}, \widehat{t'_2}, ..., \widehat{t'_k}
\}$ -- множество вытесняемых PFN'в инструкций тестового шаблона,
расположенных перед данной инструкцией.

Рассмотрим, как записываются ограничения для вытесняемого тега в
случае стратегии вытеснения LRU. А именно, имеется такая система
уравнений для вытесняемого тега $x'$:

\begin{figure}[h]
\parbox{0.4\textwidth}{
  \includegraphics[width=0.3\textwidth]{lru2}
  %\caption{Схема тестового шаблона}\label{scheme_lru}
}
\parbox{0.6\textwidth}{$$\left\{
   \begin{array}{l}
        \left[
           \begin{array}{l}
            x' \in L \wedge x' \notin \{x'_1, x'_2, ..., x'_n\}\\
            ...\\
            x' = x_i \wedge x' \notin \{x'_{i+1}, ..., x'_n\}\\
            ...\\
           \end{array}
       \right.\\
        \left[
           \begin{array}{l}
                \left\{
                    \begin{array}{l}
                        x' = y_k\\
                        R(z) \cap ( (L \setminus\{x'_1, ..., x'_n\}
                        \cup \{x_1\}\setminus\{x'_2, ..., x'_n\}\\
                        \cup ... \{x_n\}) \setminus \{ y_{k+1}, ...,
                        y_m\}) = \{y_k\}\\
                    \end{array}
                \right.\\
                ...\\
                \left\{
                    \begin{array}{l}
                        x' = \lambda_\delta\\
                        R(x') \cap ( (L \setminus\{x'_1, ..., x'_n\}
                        \cup \{x_1\}\setminus\{x'_2, ..., x'_n\}\\
                        \cup ... \{x_n\}) \setminus \{
                        \lambda_{\delta-1}, ..., \lambda_1, y_1, ...,
                        y_m\}) = \{x'\}\\
                    \end{array}
                \right.\\
           \end{array}
       \right.\\
    \widehat{x} \in M\\
   \end{array}
  \right.
$$}\end{figure}

$x_1, x_2, ..., x_n$ -- все вытесняющие тегсеты тестового шаблона в порядке  следования их инструкций, $y_1, y_2, ..., y_m$ -- все тегсеты тестового шаблона в порядке следования их инструкций ($\{x_1, ..., x_n\} \subseteq \{y_1, ..., y_m\}$), $\lambda_1, ... \lambda_w$ -- все тегсеты одного из наборов кэш-памяти в порядке <<устаревания>>.

В системе 3 части. Первая говорит о том, что вытесняемый тег
принадлежит текущему состоянию кэш-памяти (в узком смысле), т.е.
либо он был в начальном состоянии и всё еще никакой предыдущей
инструкцией не был вытеснен, либо он был внесен в кэш-памяти одним из
кэш-промахов и с того момента не был вытеснен. Вторая часть
конъюнкции говорит о том, что вытесняемый тег удовлетворяет
стратегии вытеснения LRU. Иными словами, либо последнее обращение к
вытесняемому тегу было еще в тестовом шаблоне, либо в начальном
состоянии кэш-памяти. Для каждого случая выделяются ограничения
согласно теореме~\ref{LRU_equation}. И последнее ограничение
описывает тестовую ситуацию на буфер TLB.

Имена в системе представлены на картине слева. Черные кружки
обозначают попадание в кэш-памяти, имя рядом с кружком обозначает
тегсет физического адреса. Белые кружки обозначают промах в
кэш-памяти, напротив каждого есть черта, обозначающая вытесняемый
тегсет. Стрелки заметают диапазон вытеснения -- он либо полностью
находится внутри тестового шаблона, либо включает еще и часть
начального состояния кэш-памяти. $y_k$ не обязательно будет соответствовать черному кружку, как это показано на картинке слева от системы (может быть и белый), однако это не меняет систему.

Конъюнкция первой и третьей части позволяет уменьшить размер формулы
для первой части:
$$
\left[
    \begin{array}{l}
    x' \in L \cap [M] \wedge x' \notin \{x'_1, x'_2, ..., x'_n\}\\
    ...\\
    x' = x_i \wedge \widehat{x} \in M \wedge x' \notin \{x'_{i+1}, ..., x'_n\}\\
    ...\\
    \end{array}
\right.
$$

Рассмотрим, как упростить уравнения, описывающие LRU. Сначала
рассмотрим случай, когда диапазон вытеснения начинается в начальном
состоянии:
$$
\left\{
    \begin{array}{l}
        x' = \lambda_\delta\\
        R(x') \cap ( (L \setminus\{x'_1, ..., x'_n\}
        \cup \{x_1\}\setminus\{x'_2, ..., x'_n\}
        \cup ... \{x_n\}) \setminus \{
        \lambda_{\delta-1}, ..., \lambda_1, y_1, ...,
        y_m\}) = \{x'\}\\
        \widehat{x} \in M\\
    \end{array}
\right.\\
$$

Сначала упростим второе уравнение, убрав $\{x_i\} \setminus
\{x'_{i+1}, ..., x'_n\}$, т.к. $x_i$ встречается в $\{
\lambda_{\delta-1}, ..., \lambda_1, y_1, ..., y_m\}$ :

$$
\left\{
    \begin{array}{l}
        x' = \lambda_\delta\\
        R(x') \cap L \setminus\{x'_1, ..., x'_n,
        \lambda_{\delta-1}, ..., \lambda_1, y_1, ...,
        y_m\} = \{x'\}\\
        \widehat{x} \in M\\
    \end{array}
\right.\\
$$

Избавлясь от вычитания и учитывая, что $x' \in R(x') \cap L$ при $x'
= \lambda_\delta$, получаем:

$$
\left\{
    \begin{array}{l}
        x' = \lambda_\delta\\
        x' \notin \{x'_1, ..., x'_n,
        \lambda_{\delta-1}, ..., \lambda_1, y_1, ...,
        y_m\}\\
        R(x') \cap L \setminus \{x'\} \subseteq \{x'_1, ..., x'_n,
        \lambda_{\delta-1}, ..., \lambda_1, y_1, ...,
        y_m\}\\
        \widehat{x} \in M\\
    \end{array}
\right.\\
$$

Учитывая свойства вытесняемых тегсетов и определение $R(x') \cap L = \{\lambda_w, ..., \lambda_{\delta+1}\} \cup \{x'\} \cup \{\lambda_{\delta-1}, ..., \lambda_1\}$, получаем:

$$
\left\{
    \begin{array}{l}
        x' = \lambda_\delta\\
        x' \notin \{x'_1, ..., x'_n,
        y_1, ..., y_m\}\\
        \{\lambda_w, ..., \lambda_{\delta+1}\} \subseteq
        \{x'_1, ..., x'_n, y_1, ..., y_m\}\\
        \widehat{x} \in M\\
    \end{array}
\right.\\
$$

и как дальше ?????????????????????

Другой случай -- началом диапазона вытеснения является инструкция тестового шаблона. В этом случае справедлива следующая система уравнений:
$$
\left\{
    \begin{array}{l}
        x' = y_k\\
        R(x') \cap ( (L \setminus\{x'_1, ..., x'_n\}
        \cup \{x_1\}\setminus\{x'_2, ..., x'_n\}
        \cup ... \{x_n\}) \setminus \{
        y_{k+1}, ..., y_m\}) = \{x'\}\\
        \widehat{x} \in M\\
    \end{array}
\right.\\
$$

Во втором уравнении среди $x_1, ..., x_n$ оставляем только те, которые не входят в $y_{k+1}, ..., y_m$ (это будут несколько первых элементов $x_1, ..., x_n$, обозначим их количество $p$):

$$
\left\{
    \begin{array}{l}
        x' = y_k\\
        R(x') \cap ( (L \setminus\{x'_1, ..., x'_p\}
        \cup \{x_1\}\setminus\{x'_2, ..., x'_p\}
        \cup ... \{x_p\}) \setminus \{
        x'_{p+1}, ..., x'_n, y_{k+1}, ..., y_m\}) = \{x'\}\\
        \widehat{x} \in M\\
    \end{array}
\right.\\
$$

...............

$CacheSituation(x, l1Hit, L) \wedge TLBSituation(x,
mtlbMiss, PFN, M)$:

$$
\left\{
   \begin{array}{l}
    x \in L \cap [PFN\setminus M]\\
    x \notin \{ x'_1, x'_2, ..., x'_n \}\\
    \widehat{x} \notin \{ \widehat{t_1}, \widehat{t_2}, ..., \widehat{t_k} \}\\
   \end{array}
  \right.
$$



переход к полезностям: в этих ограничениях для кодирования одного вытесняемого тегсета, нужно кодировать все предыдущие! Предлагается генерация ограничений, для которой НЕ требуется кодировать все предыдущие. Это может быть полезно, если диапазон вытеснения захватывает не все предыдущие вытесняемые тегсеты.

теорема эквивалентности

\subsubsection{unMapped-Cached случай}

\subsubsection{Разрешение уравнений на конечные множества}

\subsection{Немодульный алгоритм генерации тестовых данных более высоких уровней}

\pagebreak
\section{Выделение задач на кэш-память в архитектуре
микропроцессора}

\pagebreak
\bibliographystyle{plain}
\bibliography{theor}

\end{document}
